# MOSS - AI Assistant

> MOSS (Mobile Operating System) - A local AI chat application built with Electron + Vite + React + node-llama-cpp.
> 
> Inspired by the artificial intelligence system MOSS from Liu Cixin's "The Wandering Earth".

## âœ¨ Features

- ðŸ¤– **Local Operation**: AI models run completely locally, no internet required, protecting privacy
- ðŸ“ **Smart Management**: Visual model management interface with multiple loading options
- ðŸ’¬ **Smooth Conversation**: Friendly chat interface with Markdown rendering support
- ðŸ“Š **Real-time Monitoring**: Loading progress, token statistics, response time and other detailed information
- ðŸŽ¯ **Dual Options**: Default directory + manual selection for model loading
- ðŸ”§ **Easy to Use**: One-click installation, ready to use out of the box

## ðŸ“ Important Notice

**MOSS v1.0+ has changed the default model directory to `~/.moss/models`** for better compliance with application data storage conventions.

If you previously stored model files in the project root `./models/` folder, please run the following commands to migrate:

```bash
# Create new default directory
mkdir -p ~/.moss/models

# Migrate existing model files (if any)
mv ./models/*.gguf ~/.moss/models/ 2>/dev/null || true
mv ./models/*.bin ~/.moss/models/ 2>/dev/null || true
```

## ðŸš€ Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Prepare Model Files

#### Method 1 (Recommended): Default Directory
```bash
# Create models directory (app will auto-create)
mkdir -p ~/.moss/models

# Put .gguf files into default directory
cp your-model.gguf ~/.moss/models/
```

#### Method 2: Any Location
Place model files anywhere and use the in-app file selector to load them.

**Recommended Model Sources**:
- [Hugging Face](https://huggingface.co/models) - Search for "GGUF" format
- Popular models: Llama 2/3, Qwen, Mistral, CodeLlama, etc.

### 3. Start MOSS

```bash
npm start
```

### 4. Usage Flow

1. ðŸš€ Launch the app and go to **Model Management** page
2. ðŸ“‚ Select a model: Choose from default directory list or manually select file
3. âš¡ Click **Load** button and wait for model initialization
4. ðŸ’¬ Go to **AI Chat** page and start chatting with MOSS

## ðŸ“ Project Structure

```
MOSS/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ electron/          # Main process code
â”‚   â”‚   â””â”€â”€ index.ts       # Model loading, IPC communication logic
â”‚   â”œâ”€â”€ render/            # Renderer process code
â”‚   â”‚   â”œâ”€â”€ app.tsx        # Main app component
â”‚   â”‚   â”œâ”€â”€ pages/         # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ ModelManager.tsx    # Model management interface
â”‚   â”‚   â”‚   â””â”€â”€ ChatInterface.tsx   # AI chat interface
â”‚   â”‚   â””â”€â”€ components/    # Common components
â”‚   â”‚       â””â”€â”€ MarkdownRenderer.tsx # Markdown renderer
â”‚   â”œâ”€â”€ main.ts            # Electron main process entry
â”‚   â”œâ”€â”€ preload.ts         # Secure IPC preload script
â”‚   â””â”€â”€ renderer.tsx       # React renderer process entry
â”œâ”€â”€ scripts/               # Utility scripts
â”‚   â””â”€â”€ view-logs.js       # Log viewer
â””â”€â”€ package.json

User Data Directory:
~/.moss/
â””â”€â”€ models/                # Local model files directory
```

## ðŸ›  Tech Stack

- **ðŸ–¥ Electron**: Cross-platform desktop application framework
- **âš¡ Vite**: Modern build tool
- **âš›ï¸ React**: Declarative user interface library
- **ðŸ“˜ TypeScript**: Type-safe JavaScript
- **ðŸ¦™ node-llama-cpp**: Node.js bindings for LLaMA.cpp
- **ðŸ“ React-Markdown**: Markdown rendering support
- **ðŸ“Š Electron-Log**: Complete logging system

## ðŸ”§ Development Guide

### Development Mode

```bash
npm start
```

### Build & Release

```bash
# Package application
npm run package

# Create installer
npm run make

# Publish application
npm run publish
```

### View Logs

```bash
# View logs (with colors)
npm run logs

# Open logs directory
npm run logs:open

# Real-time log viewing
npm run logs:tail
```

## ðŸ“¡ API Interface

### Main Process IPC Interface

- `get-available-models` - Get list of models in default directory
- `select-model-file` - Open file selector to choose model
- `load-model` - Load model from specified path
- `unload-model` - Unload current model
- `get-model-status` - Get model loading status
- `chat-with-model` - Send message to model
- `get-models-directory` - Get default models directory path
- `open-directory` - Open directory in system file manager

### Renderer Process API

```typescript
// Model management
const models = await window.moss.model.getAvailableModels();
const result = await window.moss.model.loadModel(modelPath);
const status = await window.moss.model.getModelStatus();

// File operations
const fileResult = await window.moss.model.selectModelFile();
await window.moss.model.openDirectory(dirPath);

// AI chat
const response = await window.moss.model.chatWithModel("Hello, MOSS!");

// Event listeners
window.moss.model.onModelLoadingProgress((progress) => {
  console.log(`${progress.stage}: ${progress.progress}%`);
});
```

## âš™ï¸ System Requirements

### Minimum Requirements
- **Memory**: 8GB RAM (for small to medium models)
- **Storage**: 10GB available space (depends on model size)
- **OS**: Windows 10/11, macOS 10.15+, Linux

### Recommended Configuration
- **Memory**: 16GB+ RAM (for large models)
- **Processor**: Modern CPU with AVX instruction set support
- **Storage**: SSD (faster model loading)

## ðŸ” Troubleshooting

### Model Loading Failed

- âœ… Check model file format (only .gguf and .bin supported)
- âœ… Ensure sufficient system memory (at least 1.5x model size)
- âœ… Verify model file integrity
- âœ… Check application logs: `npm run logs`

### Application Startup Issues

- âœ… Confirm Node.js version >= 16
- âœ… Reinstall dependencies: `rm -rf node_modules && npm install`
- âœ… Check system compatibility (Apple Silicon requires Metal support)

### Performance Optimization

- ðŸ’¡ Close unnecessary applications to free memory
- ðŸ’¡ Use quantized model versions (e.g., Q4_0, Q5_1)
- ðŸ’¡ Adjust model context size parameters

## ðŸ“ˆ Roadmap

- [ ] ðŸŽ¨ Theme switching support
- [ ] ðŸŒ Multi-language internationalization
- [ ] ðŸ“‚ Chat history management
- [ ] ðŸ”Œ Plugin system
- [ ] ðŸš€ Model recommendation engine

## ðŸ¤ Contributing

Welcome to contribute code, report issues, or suggest improvements!

1. Fork this project
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push branch: `git push origin feature/amazing-feature`
5. Submit Pull Request

## ðŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details

## ðŸ‘¨â€ðŸ’» Author

**JinWeiyang**
- ðŸ“§ Email: jwy8645@gmail.com
- ðŸ™ GitHub: [BBBOND](https://github.com/BBBOND)

---

> ðŸ’¡ "MOSS, calculate the probability of successfully restarting the Earth's engines." - "The Wandering Earth"
> 
> Now, let MOSS provide you with localized AI intelligence services.

## ðŸ“– Language Versions

- **ä¸­æ–‡æ–‡æ¡£**: [README.md](README.md)
- **English Documentation**: README_EN.md (this file)

## ðŸ”— Additional Documentation

- [Icon Guide (English)](ICON_GUIDE_EN.md)
- [Icon Guide (ä¸­æ–‡)](ICON_GUIDE.md) 